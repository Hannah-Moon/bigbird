{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CODJ2BDEdTN"
   },
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/github/google-research/bigbird/blob/master/bigbird/summarization/eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEhLwgZwEWdw"
   },
   "source": [
    "##### Copyright 2020 The BigBird Authors\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAEheXiPEUAF"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020 The BigBird Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMotUClMFbHj"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/google-research/bigbird.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qFqiLMrtELV-"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as tft\n",
    "from tqdm import tqdm\n",
    "\n",
    "tf.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1W572kOSHHI2"
   },
   "source": [
    "## Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4oqa8sHErHq"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "path = 'gs://bigbird-transformer/summarization/pubmed/roberta/saved_model'\n",
    "imported_model = tf.saved_model.load(path, tags='serve')\n",
    "summerize = imported_model.signatures['serving_default']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../ckpt/saved_model'\n",
    "imported_model = tf.saved_model.load(path, tags='serve')\n",
    "summerize = imported_model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfw8LCz8HJze"
   },
   "source": [
    "## Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIwHE9w6FXre"
   },
   "outputs": [],
   "source": [
    "#dataset = tfds.load('scientific_papers/pubmed', split='test', shuffle_files=False, as_supervised=True)\n",
    "dataset = tfds.load('aeslc', split='test', shuffle_files=False, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset('../dataset/val_10k.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queues = tf.train.string_input_producer(['../dataset/val_10k.tfrecords'])\n",
    "\n",
    "reader = tf.TFRecordReader(options=None)\n",
    "\n",
    "_, serialized_example = reader.read(filename_queues)\n",
    "\n",
    "features = tf.parse_single_example(serialized_example,\n",
    "                                   features={\n",
    "                                       \"inputs\":tf.FixedLenFeature([], tf.string),\n",
    "                                       \"targets\":tf.FixedLenFeature([], tf.string)\n",
    "                                   }\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = features[\"inputs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"inputs\", \"targets\"]\n",
    "df = pd.read_csv('../../../pegasus/val_dd_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect at a few examples\n",
    "i = 0\n",
    "for idx, ex in df.iterrows():\n",
    "    print(idx)\n",
    "    print(ex[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00sn8AqmHxkk"
   },
   "outputs": [],
   "source": [
    "# inspect at a few examples\n",
    "i = 0\n",
    "for ex in dataset.take(1):\n",
    "    i += 1\n",
    "    print(i)\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = (tf.convert_to_tensor([ex[0]]), tf.convert_to_tensor([\"hello\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_list = []\n",
    "for idx, ex in df.iterrows():\n",
    "    tuple_list.append((tf.convert_to_tensor([ex[0]]), ex[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_fBEcJIHO0g"
   },
   "source": [
    "## Print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "W51RZ6ylHbE0"
   },
   "outputs": [],
   "source": [
    "#predicted_summary = summerize(ex[0])['pred_sent'][0]\n",
    "predicted_summary = summerize(ex[0])['pred_sent'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simplified interfaces for controllers having a dynamic schedule display. In one illustrative embodiment, a controller includes a programmable schedule and a user interface, adapted and configured to illustratively display at least a portion of the programmable schedule along a time axis and a current time indicator positioned to indicate the current time along the time axis.\n"
     ]
    }
   ],
   "source": [
    "print(predicted_summary.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35119,
     "status": "ok",
     "timestamp": 1607932440202,
     "user": {
      "displayName": "Manzil Zaheer",
      "photoUrl": "",
      "userId": "06259716656099187509"
     },
     "user_tz": 480
    },
    "id": "0ubEWsDqGFUq",
    "outputId": "dafe9305-bd33-4c8a-91b7-03fb2ec0f2b2"
   },
   "outputs": [],
   "source": [
    "print('Article:\\n {}\\n\\n Predicted summary:\\n {}\\n\\n Ground truth summary:\\n {}\\n\\n'.format(\n",
    "    ex[0].numpy(),\n",
    "    predicted_summary.numpy(),\n",
    "    ex[1].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQx9-_u6IMWI"
   },
   "source": [
    "## Evaluate Rouge Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wb4wSbmfK11B"
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from rouge_score import scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lnep7S6KIgRB"
   },
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeLsum\"], use_stemmer=True)\n",
    "aggregator = scoring.BootstrapAggregator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0VeTZT34IPoR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5402a198b15b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpredicted_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummerize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_sent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0maggregator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for ex in tqdm(dataset.take(3), position=0):\n",
    "    predicted_summary = summerize(ex[0])['pred_sent'][0]\n",
    "    score = scorer.score(ex[1].numpy().decode('utf-8'), predicted_summary.numpy().decode('utf-8'))\n",
    "    aggregator.add_scores(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = open(\"toy_predictions\", \"w\")\n",
    "target_file = open(\"toy_targets\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:57:58<00:00, 70.79s/it]\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "for ex in tqdm(tuple_list, position=0):\n",
    "    predicted_summary = summerize(ex[0])['pred_sent'][0]\n",
    "    score = scorer.score(ex[1], predicted_summary.numpy().decode('utf-8'))\n",
    "    pred_file.write(\"\\n------\" + str(idx) + '\\n')\n",
    "    target_file.write(\"\\n------\" + str(idx) + '\\n')\n",
    "    pred_file.write(predicted_summary.numpy().decode('utf-8'))\n",
    "    target_file.write(ex[1])\n",
    "    aggregator.add_scores(score)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file.close()\n",
    "target_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "p2rKqHdOKrmv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.6102031862941496, recall=0.12702973850484503, fmeasure=0.17709340479695493), mid=Score(precision=0.6511829061203225, recall=0.1540993221780352, fmeasure=0.20515268874371206), high=Score(precision=0.6871960188317057, recall=0.19267031491493897, fmeasure=0.2380927829306922)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.27048839560946314, recall=0.05803199746352736, fmeasure=0.08182212225294708), mid=Score(precision=0.30800030510167403, recall=0.07492801240523096, fmeasure=0.10109912680643926), high=Score(precision=0.3495767817632482, recall=0.09642111289469821, fmeasure=0.1229886100429452)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.5503102500224255, recall=0.10782433109291634, fmeasure=0.15496678290845947), mid=Score(precision=0.5912368506644582, recall=0.13344726561117304, fmeasure=0.1811873848772478), high=Score(precision=0.6301624828476724, recall=0.15898201405490037, fmeasure=0.20701191108495345))}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregator.aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qoB--1fiLoj1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An approach to providing discovery data records. The approach includes identifying a client computing device within a networked computing environment. The client computing device is capable of being identified within the networked computing environment.\n"
     ]
    }
   ],
   "source": [
    "print(predicted_summary.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. A method for identifying a client computing device in a networked computing environment, comprising: \n",
      "receiving a discovery data record, wherein the discovery data record includes a hardware identification and a logical identification; \n",
      "querying a plurality of client records for a matching client record; and \n",
      "if a matching client record is identified in the query, comparing the matching client record with the received discovery data record to identify the client computing device. \n",
      "21. A method for generating a discovery data record for identifying a client computing device, comprising: \n",
      "searching for an existing logical identification and hardware properties for a client computing device; \n",
      "if existing logical identification and hardware properties are located, determining if the located hardware properties are similar to existing hardware properties; and \n",
      "if it is determined that the located hardware properties are similar to the existing hardware properties, generating a discovery data record including the located logical identification and a hardware identification. \n",
      "31. In a computing device identity management system having a client computing device, a discovery data manager, and a communication path for transmitting information between the client computing device and the discovery data manager, a method for identifying a client computing device, comprising: \n",
      "receiving from the client computing device a discovery data record; \n",
      "determining if the discovery data record includes a logical identification; \n",
      "if it is determined that the discovery data record includes a logical identification: \n",
      "determining if the logical identification matches a logical identification of a client record; \n",
      "obtaining the client record; \n",
      "if it is determined that the discovery data record does not include a logical identification: \n",
      "obtaining a client record that includes key data that matches key data of the discovery data record; and \n",
      "identifying the client computing device based on the obtained client record. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ex[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {},
   "name": "UseSavedModel.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
